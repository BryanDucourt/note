## task1

| Min V | Min P      | Iter |
| ----- | ---------- | ---- |
| -1.25 | [-1.0,1.5] | 2    |
## task2
Problem a:
Golden Section Search - Minimum value: -1.12 at 0.26 - iterations : 8
Fibonacci Search - Minimum value: -1.12 at 0.26 - iterations : 7
Bisection Search - Minimum value: -1.12 at 0.23 - iterations : 6
Shubert-Piyavskii - Minimum value: -0.97 at -0.03 - iterations : 3

Problem b:
Golden Section Search - Minimum value: -39.88 at 3.61 - iterations : 12
Fibonacci Search - Minimum value: -39.88 at 3.61 - iterations : 12
Bisection Search - Minimum value: -39.88 at 3.59 - iterations : 9
Shubert-Piyavskii - Minimum value: -1.0 at 0 - iterations : 1

## task3
Goldstein step size: 0.9999995231628418, iterations: 20
Wolfe-Powell step size: 0.00390625, iterations: 8

## task4
### (a)
由次梯度定义$\partial f(x)= \{g|f(y)\ge f(x)+g^T(y-x),\forall y\in\text{dom} f \}$
$$
\begin{aligned}
f(x)\ge f(0)+g^Tx \\
\max\{|x|\}\ge 0+g^Tx\\
\max\{|x|\}\ge g^Tx
\end{aligned}
$$
因此有$||g||_1\le1$
## (b)
$$
	f(x)\ge f(0)+gx \gets \{\begin{aligned}
	x\gt0,g\lt\frac{e^x-1}{x},s.t.g\lt lim_{x\to 0^+}\frac{e^x-1}{x}=1\\
	x\lt0,g\lt\frac{e^{-x}-1}{x},s.t.g\gt lim_{x\to 0^-}\frac{e^{-x}-1}{x}=-1
	\end{aligned}
$$
因此次梯度g=[-1,1]
## (c)
$$
\begin{aligned}
\partial f = conv \cup_{i\in I(x)}\partial f_i(x)\\
\partial f_1(x) = A_1,A_1 = (1,1)^T\\
\partial f_2(x) = A_2, A_2 = (1,-1)^T
\end{aligned}
$$
## task5
Minimum point: [-2.77555756e-17  0.00000000e+00]
Function value at minimum: 7.703719777548943e-33
Number of iterations: 2

## task6
Minimum point: [2. 1.]
Function value at minimum: -8.0
Number of iterations: 2

## task7
DFP Minimum point: [-1.   1.5]
DFP Function value at minimum: -1.25
DFP Number of iterations: 2
BFGS Minimum point: [-1.   1.5]
BFGS Function value at minimum: -1.25
BFGS Number of iterations: 2
Fletcher-Reeves CG Minimum point: [-1.   1.5]
Fletcher-Reeves CG Function value at minimum: -1.25
Fletcher-Reeves CG Number of iterations: 2
分析：

DFP 法和 BFGS 法都是拟牛顿法，主要是为了解决牛顿法中 Hesse 逆矩阵不可解的问题。可以验证，DFP 法和 BFGS 法提出的矫正矩阵能够得到满足拟牛顿条件的矩阵。
DFP提出的矫正矩阵为
$$ H_{k+1} = H_k + \frac{(y_k y_k^\top)}{y_k^\top s_k} - \frac{(H_k s_k s_k^\top H_k)}{s_k^\top H_k s_k}

$$
可以验证DFP法构造的$H_k$矩阵都是对称正定矩阵，故每次搜索方向均是函数下降方向。在目标函数是二次函数 $f(x) = \frac12 x^T Ax + b^T x + c$ 时，可以证明 DFP 法构造的搜索方向是关于 A 的一组共轭方向，有限步迭代收敛至极值点。
和 DFP 法直接估计 Hesse 的逆矩阵不同，BFGS 法的想法是先估计 Hesse 矩阵本身，然后经过变换，可以得到 BFGS 法的矫正公式.
实际计算经验表明 BFGS 法的数值稳定性更好。拟牛顿算法是无约束优化问题中最有效的一类算法，在实际计算中规避了二次导数的计算（用一阶导数近似），当构造的 Hk 正定时，搜索方向都是下降方向，且具有二次终结性，对于更一般的情况，具有超线性的收敛速度。但是，拟牛顿法需要较大的存储空间，在求解大型问题可能会遇到困难。
## task8

梯度下降法的收敛性证明

考虑如下的无约束优化问题：
$min⁡x∈Rnf(x)\min_{x \in \mathbb{R}^n} f(x)$

其中 f(x)f(x) 是**光滑的强凸函数**，满足以下条件：

- f∈C1f \in C^1 且具有 **L-Lipschitz 连续梯度**：
    
    ∥∇f(x)−∇f(y)∥≤L∥x−y∥,∀x,y\|\nabla f(x) - \nabla f(y)\| \leq L \|x - y\|, \quad \forall x, y
- **强凸性参数为 μ>0\mu > 0**，即：
    
    f(y)≥f(x)+∇f(x)T(y−x)+μ2∥y−x∥2f(y) \geq f(x) + \nabla f(x)^T (y - x) + \frac{\mu}{2}\|y - x\|^2

### 1.2 梯度下降迭代格式

xk+1=xk−α∇f(xk)x_{k+1} = x_k - \alpha \nabla f(x_k)

当步长 α∈(0,2L)\alpha \in \left(0, \frac{2}{L}\right) 时，算法收敛。

### 1.3 收敛性定理

如果 ff 是 μ\mu-强凸且具有 L-Lipschitz 连续梯度，那么梯度下降法具有**线性收敛率**：

f(xk)−f(x∗)≤(1−αμ)k(f(x0)−f(x∗)),当 α≤1Lf(x_k) - f(x^*) \leq \left(1 - \alpha \mu\right)^k (f(x_0) - f(x^*)), \quad \text{当 } \alpha \le \frac{1}{L}

或者在二范数下有：

∥xk−x∗∥≤(1−αμ)k∥x0−x∗∥\|x_k - x^*\| \leq \left(1 - \alpha \mu\right)^k \|x_0 - x^*\|

---

## 二、牛顿法的收敛性证明

### 2.1 牛顿法迭代格式

xk+1=xk−[∇2f(xk)]−1∇f(xk)x_{k+1} = x_k - \left[\nabla^2 f(x_k)\right]^{-1} \nabla f(x_k)

### 2.2 收敛性条件

假设：

- f∈C2f \in C^2
    
- x∗x^* 是 f(x)f(x) 的局部极小点，且 ∇2f(x∗)≻0\nabla^2 f(x^*) \succ 0
    
- ∇2f(x)\nabla^2 f(x) 在 x∗x^* 的邻域内是 Lipschitz 连续的
    

### 2.3 收敛性结论

在上述条件下，牛顿法具有**二次收敛性**：

∥xk+1−x∗∥≤C∥xk−x∗∥2\|x_{k+1} - x^*\| \leq C \|x_k - x^*\|^2

当接近最优点时，收敛速度远快于梯度下降。

---

## 三、梯度下降法求解二次规划问题的收敛性分析

### 3.1 问题定义：二次规划（QP）

考虑标准形式的二次规划问题：

min⁡x∈Rn12xTQx+cTxs.t. Ax≤b\min_{x \in \mathbb{R}^n} \frac{1}{2} x^T Q x + c^T x \\ \text{s.t. } Ax \leq b

其中 Q⪰0Q \succeq 0，是对称正定或半正定矩阵。

为简化分析，我们考虑无约束形式（即经典二次函数最小化）：

f(x)=12xTQx+cTxf(x) = \frac{1}{2} x^T Q x + c^T x

### 3.2 梯度下降法的收敛性

对于该目标函数：

- 梯度为 ∇f(x)=Qx+c\nabla f(x) = Qx + c
    
- 如果 Q≻0Q \succ 0，那么 f(x)f(x) 是强凸的，且具有 Lipschitz 连续梯度，Lipschitz 常数为最大特征值 L=λmax⁡(Q)L = \lambda_{\max}(Q)，强凸参数为 μ=λmin⁡(Q)\mu = \lambda_{\min}(Q)
    

因此满足梯度下降法收敛的所有条件：

xk+1=xk−α(Qxk+c)x_{k+1} = x_k - \alpha (Qx_k + c)

当步长 α∈(0,2λmax⁡(Q))\alpha \in \left(0, \frac{2}{\lambda_{\max}(Q)}\right) 时，梯度法线性收敛：

∥xk−x∗∥≤(1−αμ)k∥x0−x∗∥\|x_k - x^*\| \leq \left(1 - \alpha \mu\right)^k \|x_0 - x^*\|

### 3.3 收敛速度依赖于条件数

令 κ=λmax⁡(Q)λmin⁡(Q)\kappa = \frac{\lambda_{\max}(Q)}{\lambda_{\min}(Q)}，则：

- 梯度法线性收敛，速率为 1−1κ1 - \frac{1}{\kappa}
    
- 当 κ\kappa 较大时（即 Q 条件数大），收敛慢
    

---

## 总结

|方法|收敛性|收敛速度|条件|
|---|---|---|---|
|梯度下降法|线性收敛|O((1−μ/L)k)O((1 - \mu/L)^k)|ff 强凸，L-Lipschitz 梯度|
|牛顿法|二次收敛|O(∥xk−x∗∥2)O(\\|x_k - x^*\\|^2)|Hessian 正定且连续|

对于二次规划问题（尤其是无约束二次函数），梯度下降法可以保证线性收敛，但牛顿法更快。若考虑约束问题，可配合投影、KKT 条件或使用内点法等。

如需进一步推导带不等式约束的二次规划中梯度投影法的收敛性，也可以继续深入讨论。是否要补充这一部分？
## task9
无约束优化问题求解基本思想：
无约束优化问题的求解主要有两大类算法：
- 一类是利用导数信息的算法，包括最速下降法，牛顿法，共轭梯度法，拟牛顿法。这类方法是利用梯度信息，来选取合适的搜索方向，搜索方向要要满足使得函数值下降的要求。
- 另一类算法是不利用导数信息的直接优化方法，包括模式搜索，Rosenbrock 法，单纯形搜索，Powell 方法等，实际上是根据规则在空间中挑选线性无关的搜索方向，自然地，这类方法对于求解变量不多的优化问题比较有效。
一般而言，无约束优化问题的求解涉及两个关键的问题，一个是确定当前点的搜索方向，二是确定搜索步长。
如何将非凸优化问题转化成凸优化问题：
首先需要说明相比于非凸问题，凸问题的优势。对于凸问题，局部最优解就是全局最优解（更准确的说法是严格凸函数），同时，非凸问题的困难在于在高维空间中，存在许多鞍点（梯度为零，但是Hesse 矩阵不定）。

回顾凸问题的定义，需要满足两个条件（1）问题的可行域是一个凸集（2）目标函数是可行域上的一个凸函数。

在非凸问题转化成凸问题的过程中可以从这两个方向入手：

- 修改目标函数，使其成为一个凸函数，这样就可以满足条件（1）。
- 抛弃一些约束条件，或者对约束条件做松弛处理，使得新的可行域是凸集，同时包含原可行域的所有点。

如何将有约束问题转化成无约束优化问题：

可以将对于可行域的约束条件作为惩罚项加入到原目标函数中，比如常见的罚函数方法（内点法，外点法）；同时为了解决罚函数方法中的缺陷，提出了增广拉格朗日方法。
## task11
选择task5中的优化问题，使用带有动量的梯度下降优化，结果如下
Minimum point: [-4.50350344e-08 -1.10325262e-07]
Function value at minimum: 3.245320676919942e-14
Number of iterations: 268