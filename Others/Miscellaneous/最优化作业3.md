# task1
在优化问题中，**迭代**与**逼近**是寻找最优解的两大核心思想。**迭代**指的是从一个初始猜测开始，通过不断重复更新步骤来生成一系列解，直至满足终止条件；**逼近**则是指利用简化模型（如一阶或二阶局部展开）来近似原问题，使得每次迭代都在更可控的子问题上寻找更优解。二者结合，既保证了算法的可操作性，又能在有限步骤内逐步收敛至最优或近似最优解。
## 迭代思想

- **定义**：迭代是一种算法框架，其中每一次“迭代”都会根据上一次的结果产生新的近似解，形成一条解序列，直到达到一定精度或满足其他终止条件为止。
- **特点**：
    1. **初始点依赖**：需要指定一个或多个初始猜测；
    2. **更新规则**：每次迭代按照预先定义的公式或搜索策略更新当前解；
    3. **收敛监测**：通过判断目标函数的变化量或解的变化量来决定是否终止。
- **典型引用**：在数值计算中，迭代方法是解大型线性/非线性问题的常用手段，直接方法往往因计算量或存储量过大而不适用，迭代方法通过可控的重复计算来“逐步优化”
## 逼近思想
- **定义**：逼近是在当前解附近，用一个更易处理的模型（如一阶线性模型或二阶二次模型）来近似原函数，以便在子问题上快速计算下一步迭代。
- **作用**：
    1. **降低复杂度**：将原问题的复杂结构简化为局部可解的子问题；
    2. **加速收敛**：借助更高阶信息（如 Hessian 矩阵）或更好的模型，使每次迭代距离最优解更近；
    3. **保证可行性**：通过可控的近似误差，确保每一步更新的合理性。
- **典型引用**：以牛顿法为例，每次迭代都基于当前点的**二阶泰勒展开**来构造二次近似子问题，并求解该子问题的最优解作为下一迭代点

# task2
$$
\begin{aligned}
∇hj​(xk​)Td=0\\
∇gi​(xk​)Td≤0\\
∇f(xk​)Td<0
\end{aligned}
$$
# task3
目标函数梯度为$\nabla f(x)=\left ( \begin{aligned}1+4x_1+2x_2\\-1 +2x_2+2x_1\end{aligned}\right )$
$x_0=(0,0)^T$，代入得$d_0=-\nabla f(x_0)=(-1,1)$，设搜索步长为$\lambda_0$，解$\nabla \phi(\lambda_0)=2\lambda_0-2$，解得$\lambda_0=1$，即$x_1=(-1,1)^T$。
$x_1=(-1,1)^T$，代入得$d_1=-\nabla f(x_1)=(1,1)$，设搜索步长为$\lambda_1$，解$\nabla \phi(\lambda_1)=10\lambda_1-2$，解得$\lambda_1=\frac15$，即$x_2=(-\frac45,\frac65)^T$。

# task4










# task5








# task6
(1) 证明 Lagrange 对偶方程 (Lagrange dual function) 是 concave 的.
Proof. 首先考虑拉格朗日方程中 L(x, u, v) 中，对于每一个固定的 x，L(x, u, v) 对于 (u, v) 都是仿射的，根据仿射函数的性质（仿射函数即是凸的也是凹的），可以得到 L(x, u, v) 对 (u, v) 是凹的.θ(u, v) 是对 L(x, u, v) 取 pointwise infimum 的结果，所以 θ(u, v) 是凹的.
(2) 对偶问题在最优化中的作用：通过 (1) 中的证明我们可以知道，一个优化问题的拉格朗日对偶问题一定是一个凹问题，这对于原问题的目标函数和不等式约束的凸性没有要求。同时，对偶的性质还保证的对偶问题的最优解一定是原问题的下界，即有 θ(u, v) ≤ p ∗ , ∀u ≥ 0,∀v，其中 p ∗ 是原问题的最优解，在弱对偶定理和强对偶定理的帮助下，可以很容易的估计原问题的最优解的界，甚至将原问题转换成对偶问题求解.

# task7










# task8








# task9
启发式算法基本思想: 在可接受的计算代价下找到最好的解，但不一定能保证解的最优性，是一种近似算法. 通常是基于某种直观感觉或者经验构造的算法，在解决大规模，复杂的组合优化问题是有较好的表现。与最优化算法不同，启发式算法不需要提供一个最优解，而是提供一个在可接受精度范围内的解，是精度和速度的权衡.
下面尝试给出点集匹配问题的启发式算法，首先形式化描述该问题，设点集 P, Q 分别是模板点集和目标点集，求映射 f(pi) = qj , ∀pi ∈ P，目标函数通常定义为 g(P, Q) = ∑i,j∈P d(pi , pj ) − d(f(pi) −f(pj )) + λ(nP − nP ′)，其中 f(pi) 是目标点集的一个点，pi 是模板点集的一个点, d(pi , pj ) 是 P 中两个点的距离，nP , nP ′, λ 分别是模板点集中的点总个数，模板点集中匹配上的点个数和惩罚系数. 显然，惩罚系数越大，强迫找到一个该问题的最大匹配.
问题的难点在于如何得到映射 f，考虑实际问题，可能是一个非线性的映射，如何建模该映射，以及如何找到一个最优的映射.
可以考虑用人工神经网络来建模该映射，直观上的理解神经网络是一个通用的函数拟合模型，对于神经网络参数的学习，可以通过引入模拟退火算法的随机梯度下降来获得一个较优的参数解. 可能
存在的问题是有监督学习可能需要大量的样本对，对于图像的点集匹配问题，可以收集一定数量的图片，然后通过随机裁剪来获得样本对，尝试训练模型，得到问题的解.
# task10
几种求解大规模问题的分布式优化算法: 可以简单的将分布式优化算法按照有无中心节点分成两类

• 有中心节点算法基本思想是每个节点计算自身梯度，将信息传递给中心节点，中心节点汇聚所有节点信息后计算决策变量，然后将决策变量回传给各个子节点.常见的有中心节点的分布式优化算法有 ADMM，PSGD 等，其优点是收敛速度快，但是缺点是中心节点需要收集所有局部节点的信息有较大的延迟，中心节点需要较大的带宽，优化的过程也不够鲁棒.

• 无中心节点算法基本思想是每个节点计算自身梯度，然后将信息传递给邻居，每个节点通过自身和邻居节点的信息更新.常见的有分布式梯度下降算法 DGD，其优点是通信负载均衡到每一个节点，鲁棒性和隐私性都好。缺点是算法的设计需要单独考虑

# task11
罚因子方法: 将约束作为惩罚条件加入目标函数中，得到一个原约束问题的无约束辅助问题，利用无约束优化算法进行求解。主要有内点法和外点法两种形式.

• 外点法：可以处理等式约束和不等书约束的情况，通过添加惩罚项，迫使迭代点向约束的可行域靠近. 由于初始点的选取可以在约束可行域外随机选取，称为外点法.
• 内点法：只能处理不等式约束的情况，将惩罚添加在约束集边界，当可行解在约束界内，约束较小（可忽略），当解在约束界外惩罚趋于无穷大，又称闸函数法. 需要注意内点的的初始点和迭代点需要在约束可行域内.

罚函数法通过构造辅助问题，将约束优化问题转换成无约束优化问题求解，但是辅助问题的最优解想要达到对原问题解的较好近似，常常需要罚因子趋于无穷，此时出现了 0 ∗ ∞ 的情况，会出现较大误差，实际求解很不方便.

增广拉格朗日方法的基本思想是通过将约束条件作为惩罚项加入拉格朗日函数，得到增广的拉格朗日函数，这样做的好处是利用了拉格朗日函数在 KKT 点导数为零的稳定性条件克服了罚函数法中因为 ∇f(x) = 0 而出现的困难. 同时，相比于拉格朗日法，增广后的方法也有明显的好处，即不再需要交替求解原始问题和对偶问题的解，同时算法的速度和稳定性也有很大的提升，不再依靠每次搜索的步长. 实际上增广拉格朗日方法通过收敛性定理保证了对于大多数惩罚因子 c 都有着不错的收敛性，而且仅仅需要关注求解对偶问题的解，即可通过解优化问题得到原始问题的解.

# task12
将非凸问题转换成凸问题的常用方法总结.

首先需要说明相比于非凸问题，凸问题的优势。对于凸问题，局部最优解就是全局最优解（更准确的说法是严格凸函数），同时，非凸问题的困难在于在高维空间中，存在许多鞍点（梯度为零，但是Hesse 矩阵不定）。

回顾凸问题的定义，需要满足两个条件（1）问题的可行域是一个凸集（2）目标函数是可行域上的一个凸函数。
在非凸问题转化成凸问题的过程中可以从这两个方向入手：
• 修改目标函数，使其成为一个凸函数，这样就可以满足条件（1）。
• 抛弃一些约束条件，或者对约束条件做松弛处理，是的新的可行域是凸集，同时包含原可行域的所有点。